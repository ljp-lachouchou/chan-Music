from fastapi import FastAPI, HTTPException, BackgroundTasks, Body
from fastapi.middleware.cors import CORSMiddleware
from fastapi.staticfiles import StaticFiles
from contextlib import asynccontextmanager
import uvicorn
import uuid
import os
import multiprocessing
import logging
import time
import warnings
import asyncio
from typing import Dict

# æœ¬åœ°æ¨¡å—
from musicgen import AudioGenerator
task_status: Dict[str, dict] = {}
# é…ç½®å¸¸é‡
MODEL_PATH = "C:/Users/å¢ä¿Šæ¾/.cache/huggingface/hub/models--facebook--musicgen-small"
TEMP_DIR = os.path.abspath("./temp_audio")
os.makedirs(TEMP_DIR, exist_ok=True)

# é…ç½®æ—¥å¿—
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("AudioGenAPI")

# Windowså¤šè¿›ç¨‹é…ç½®
if os.name == 'nt':
    try:
        multiprocessing.set_start_method('spawn')
    except RuntimeError:
        pass
mp_ctx = multiprocessing.get_context('spawn')

# è¿›ç¨‹é—´é€šä¿¡é˜Ÿåˆ—
TASK_QUEUE = mp_ctx.Queue(maxsize=100)
RESULT_QUEUE = mp_ctx.Queue(maxsize=100)
task_events: Dict[str, asyncio.Event] = {}
result_queue_listener = None

class ModelWorker:
    """å¢å¼ºç‰ˆæ¨¡å‹å·¥ä½œå™¨"""

    def __init__(self, model_path, temp_dir):
        self.model_path = model_path
        self.temp_dir = temp_dir
        self._model = None

    def initialize(self):
        """æ˜¾å¼åˆå§‹åŒ–æ¨¡å‹"""
        logger.info(f"ğŸ”§ åˆå§‹åŒ–æ¨¡å‹å·¥ä½œå™¨ | PID: {os.getpid()}")
        self._model = AudioGenerator(self.model_path, self.temp_dir)
        # è§¦å‘æ¨¡å‹åŠ è½½
        _ = self._model.synthesiser
        logger.info(f"âœ… æ¨¡å‹åŠ è½½å®Œæˆ | å†…å­˜: {self.get_memory_usage()} MB")

    def get_memory_usage(self):
        """è·å–è¿›ç¨‹å†…å­˜ä½¿ç”¨"""
        import psutil
        process = psutil.Process(os.getpid())
        return process.memory_info().rss / 1024**2

    def process_task(self, task: dict):
        """å¤„ç†ç”Ÿæˆä»»åŠ¡"""
        try:
            logger.info(f"ğŸµ å¼€å§‹ç”Ÿæˆ: {task['task_id']}")
            result = self._model.generate(task["text"])
            self._model.save_audio(task["filename"], result)
            return {"status": "success", "filename": task["filename"]}
        except Exception as e:
            logger.error(f"ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {"status": "failed", "error": str(e)}


def worker_process(task_queue, result_queue, model_path, temp_dir):
    """å¢åŠ è°ƒè¯•æ—¥å¿—çš„å·¥ä½œè¿›ç¨‹"""
    logger = logging.getLogger("WorkerProcess")
    try:
        logger.info(f"ğŸ”„ å·¥ä½œè¿›ç¨‹ {os.getpid()} å¯åŠ¨")

        # åˆå§‹åŒ–é˜¶æ®µ
        logger.info("â³ åˆ›å»ºç”Ÿæˆå™¨å®ä¾‹...")
        worker = ModelWorker(model_path, temp_dir)

        logger.info("ğŸ”¥ å¼€å§‹åˆå§‹åŒ–æ¨¡å‹...")
        worker.initialize()  # æ˜¾å¼åˆå§‹åŒ–

        logger.info("ğŸš€ è¿›å…¥ä»»åŠ¡å¤„ç†å¾ªç¯")
        while True:
            task = task_queue.get()
            if task is None:
                logger.info("ğŸ›‘ æ”¶åˆ°ç»ˆæ­¢ä¿¡å·")
                break

            logger.info(f"ğŸ“¥ æ”¶åˆ°ä»»åŠ¡: {task['task_id']}")
            result = worker.process_task(task)

            logger.info(f"ğŸ“¤ æäº¤ç»“æœ: {task['task_id']}")
            result_queue.put({
                "task_id": task["task_id"],
                "status": result["status"],
                "filename": task["filename"]
            })

    except Exception as e:
        logger.error(f"ğŸ’¥ å·¥ä½œè¿›ç¨‹å´©æºƒ: {str(e)}", exc_info=True)
        result_queue.put({
            "task_id": "SYSTEM_ERROR",
            "status": "failed",
            "error": f"Worker Crash: {str(e)}"
        })


# æ–°å¢é˜Ÿåˆ—ç›‘å¬åç¨‹
async def listen_result_queue():
    """è·¨è¿›ç¨‹é˜Ÿåˆ—ç›‘å¬å™¨ï¼ˆå…³é”®å®ç°ï¼‰"""
    while True:
        try:
            # ä½¿ç”¨çº¿ç¨‹æ± å¤„ç†é˜»å¡æ“ä½œ
            result = await asyncio.get_event_loop().run_in_executor(
                None,
                lambda: RESULT_QUEUE.get(timeout=0.1)
            )

            task_id = result["task_id"]
            if task_id in task_events:
                task_events[task_id].set()
                del task_events[task_id]

        except multiprocessing.queues.Empty:
            await asyncio.sleep(0.1)
        except Exception as e:
            logger.error(f"é˜Ÿåˆ—ç›‘å¬é”™è¯¯: {str(e)}")
@asynccontextmanager
async def lifespan(app: FastAPI):
    """å¢å¼ºçš„ç”Ÿå‘½å‘¨æœŸç®¡ç†"""
    num_workers = min(4, os.cpu_count() or 1)
    processes = []

    try:
        logger.info(f"ğŸš€ å¯åŠ¨ {num_workers} ä¸ªå·¥ä½œè¿›ç¨‹...")

        # åˆ›å»ºå·¥ä½œè¿›ç¨‹
        for i in range(num_workers):
            p = mp_ctx.Process(
                target=worker_process,
                args=(TASK_QUEUE, RESULT_QUEUE, MODEL_PATH, TEMP_DIR)
            )
            p.start()
            processes.append(p)
            logger.info(f"ğŸ”„ å¯åŠ¨å·¥ä½œè¿›ç¨‹ {i + 1}/{num_workers}")
            time.sleep(10)  # ç¡®ä¿é¡ºåºåˆå§‹åŒ–

        # éªŒè¯æ¨¡å‹åŠ è½½
        logger.info("ğŸ” éªŒè¯æ¨¡å‹åŠ è½½çŠ¶æ€...")
        TASK_QUEUE.put({
            "task_id": "health_check",
            "text": "test sound",
            "filename": "health_check.wav",
            "temp_dir": TEMP_DIR  # æ·»åŠ ç¼ºå¤±çš„å¿…é¡»å­—æ®µ
        })

        # ç­‰å¾…éªŒè¯ç»“æœ
        start_time = time.time()
        while time.time() - start_time < 120:  # 2åˆ†é’Ÿè¶…æ—¶
            if not RESULT_QUEUE.empty():
                result = RESULT_QUEUE.get()
                if result["task_id"] == "health_check":
                    if result.get("status") == "success":  # ç›´æ¥è®¿é—®statuså­—æ®µ
                        logger.info("âœ… æ‰€æœ‰æ¨¡å‹åŠ è½½éªŒè¯é€šè¿‡")
                        break
                    else:
                        logger.error("âŒ æ¨¡å‹åŠ è½½éªŒè¯å¤±è´¥")
                        raise RuntimeError("æ¨¡å‹åŠ è½½å¤±è´¥")
            await asyncio.sleep(2)
        else:
            raise TimeoutError("æ¨¡å‹åŠ è½½éªŒè¯è¶…æ—¶")

        global result_queue_listener
        result_queue_listener = asyncio.create_task(listen_result_queue())

        yield

        # æ¸…ç†ç›‘å¬ä»»åŠ¡
        result_queue_listener.cancel()
        try:
            await result_queue_listener
        except asyncio.CancelledError:
            pass

    finally:
        logger.info("ğŸ›‘ æ¸…ç†èµ„æº...")
        # å‘é€ç»ˆæ­¢ä¿¡å·
        for _ in range(num_workers):
            TASK_QUEUE.put(None)
        # ç­‰å¾…è¿›ç¨‹é€€å‡º
        for p in processes:
            p.join(timeout=30)
            if p.exitcode is None:
                p.terminate()


app = FastAPI(
    title="AudioGen API - Stable",
    lifespan=lifespan
)

# è·¨åŸŸé…ç½®
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],
    allow_methods=["*"],
    allow_headers=["*"],
)


# ä¿®æ”¹ç”Ÿæˆç«¯ç‚¹
@app.post("/generate")
async def generate_audio(text: str = Body(..., embed=True)):
    task_id = str(uuid.uuid4())
    filename = f"{task_id}.wav"

    # åˆ›å»ºå¼‚æ­¥äº‹ä»¶
    completion_event = asyncio.Event()
    task_events[task_id] = completion_event

    # æäº¤ä»»åŠ¡åˆ°é˜Ÿåˆ—
    TASK_QUEUE.put({
        "task_id": task_id,
        "text": text,
        "filename": filename,
        "temp_dir": TEMP_DIR
    })

    # ç­‰å¾…ä»»åŠ¡å®Œæˆé€šçŸ¥
    await completion_event.wait()

    # è¿”å›æœ€ç»ˆå“åº”
    return {
        "task_id": task_id,
        "audio_url": f"http://myredisapi.com/audio/{filename}"
    }


@app.get("/tasks/{task_id}")
async def get_task_status(task_id: str):
    file_path = os.path.join(TEMP_DIR, f"{task_id}.wav")
    status = {
        "status": "not_found",
        "filename": task_id + ".wav"
    }
    if os.path.exists(file_path):
        status.update({
            "status": "completed",
            "audio_url": f"http://myredisapi.com/audio/{task_id}.wav"
        })
    elif task_id in task_status:
        status = task_status[task_id]

    return status


@app.get("/health")
async def health_check():
    return {
        "status": "ready",
        "workers": len(multiprocessing.active_children()),
        "queue_size": TASK_QUEUE.qsize()
    }
# é™æ€æ–‡ä»¶è·¯ç”±
app.mount("/audio", StaticFiles(directory=TEMP_DIR), name="audio")

if __name__ == "__main__":
    multiprocessing.freeze_support()
    uvicorn.run(
        app,
        host="0.0.0.0",
        port=8000,
        workers=1,
        log_level="info"
    )